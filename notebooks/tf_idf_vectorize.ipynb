{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c487d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a778297d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/arnav/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "770922b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/arnav/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f0505ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/arnav/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c010d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c69d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711c7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"cord.db\")\n",
    "df = pd.read_sql_query(\"SELECT title, abstract, authors, body_text FROM cord19\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69ec834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
       "      <td>OBJECTIVE: This retrospective chart review des...</td>\n",
       "      <td>Madani, Tariq A; Al-Ghamdi, Aisha A</td>\n",
       "      <td>Mycoplasma pneumoniae is a common cause of upp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
       "      <td>Inflammatory diseases of the respiratory tract...</td>\n",
       "      <td>Vliet, Albert van der; Eiserich, Jason P; Cros...</td>\n",
       "      <td>Since its discovery as a biological messenger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surfactant protein-D and pulmonary host defense</td>\n",
       "      <td>Surfactant protein-D (SP-D) participates in th...</td>\n",
       "      <td>Crouch, Erika C</td>\n",
       "      <td>Surfactant protein-D (SP-D) is a member of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Role of endothelin-1 in lung disease</td>\n",
       "      <td>Endothelin-1 (ET-1) is a 21 amino acid peptide...</td>\n",
       "      <td>Fagan, Karen A; McMurtry, Ivan F; Rodman, David M</td>\n",
       "      <td>from Xenopus laevis [16] . ETA receptors in no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gene expression in epithelial cells in respons...</td>\n",
       "      <td>Respiratory syncytial virus (RSV) and pneumoni...</td>\n",
       "      <td>Domachowske, Joseph B; Bonville, Cynthia A; Ro...</td>\n",
       "      <td>RSV and PVM are viruses of the family Paramyxo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Clinical features of culture-proven Mycoplasma...   \n",
       "1  Nitric oxide: a pro-inflammatory mediator in l...   \n",
       "2    Surfactant protein-D and pulmonary host defense   \n",
       "3               Role of endothelin-1 in lung disease   \n",
       "4  Gene expression in epithelial cells in respons...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  OBJECTIVE: This retrospective chart review des...   \n",
       "1  Inflammatory diseases of the respiratory tract...   \n",
       "2  Surfactant protein-D (SP-D) participates in th...   \n",
       "3  Endothelin-1 (ET-1) is a 21 amino acid peptide...   \n",
       "4  Respiratory syncytial virus (RSV) and pneumoni...   \n",
       "\n",
       "                                             authors  \\\n",
       "0                Madani, Tariq A; Al-Ghamdi, Aisha A   \n",
       "1  Vliet, Albert van der; Eiserich, Jason P; Cros...   \n",
       "2                                    Crouch, Erika C   \n",
       "3  Fagan, Karen A; McMurtry, Ivan F; Rodman, David M   \n",
       "4  Domachowske, Joseph B; Bonville, Cynthia A; Ro...   \n",
       "\n",
       "                                           body_text  \n",
       "0  Mycoplasma pneumoniae is a common cause of upp...  \n",
       "1  Since its discovery as a biological messenger ...  \n",
       "2  Surfactant protein-D (SP-D) is a member of the...  \n",
       "3  from Xenopus laevis [16] . ETA receptors in no...  \n",
       "4  RSV and PVM are viruses of the family Paramyxo...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df24ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "# documents = df['abstract'].str.lower().apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5937a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk_stop_words = nltk.corpus.stopwords.words('english')\n",
    "# documents_without_stop_words = []\n",
    "# for document in documents :\n",
    "#     documents_without_stop_words.append([word for word in document if word not in nltk_stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d078d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordnet_lemmatizer = WordNetLemmatizer()\n",
    "# for i, document in enumerate(documents_without_stop_words) :\n",
    "#     documents_without_stop_words[i] = [wordnet_lemmatizer.lemmatize(word) for word in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e4bb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['title']\n",
    "authors = df['authors']\n",
    "abstracts = df['abstract']\n",
    "body_texts = df['body_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "403f45d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokenizer = nltk.RegexpTokenizer(r'[A-Za-z]+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    " \n",
    "    nltk_stop_words = nltk.corpus.stopwords.words('english')\n",
    "    tokens = [token for token in tokens if token not in nltk_stop_words]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(t.lower()) for t in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e6cdfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=preprocess_text, min_df=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0da8f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tf_idf_fit = vectorizer.fit(titles + abstracts + body_texts)\n",
    "\n",
    "title_tf_idf = vectorizer.transform(titles)\n",
    "document_tf_idf = vectorizer.transform(abstracts + body_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0df3342b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>aberrant</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>abnormality</th>\n",
       "      <th>about</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>z</th>\n",
       "      <th>zhang</th>\n",
       "      <th>zika</th>\n",
       "      <th>zikv</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoonosis</th>\n",
       "      <th>zoonotic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4480 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          a   aa   ab  abdominal  aberrant  ability  able  abnormal  \\\n",
       "0  0.010853  0.0  0.0        0.0       0.0      0.0   0.0   0.00000   \n",
       "1  0.010684  0.0  0.0        0.0       0.0      0.0   0.0   0.00000   \n",
       "2  0.020979  0.0  0.0        0.0       0.0      0.0   0.0   0.05072   \n",
       "3  0.012485  0.0  0.0        0.0       0.0      0.0   0.0   0.00000   \n",
       "4  0.017373  0.0  0.0        0.0       0.0      0.0   0.0   0.00000   \n",
       "\n",
       "   abnormality  about  ...     young  younger    z  zhang  zika  zikv  zinc  \\\n",
       "0          0.0    0.0  ...  0.030971      0.0  0.0    0.0   0.0   0.0   0.0   \n",
       "1          0.0    0.0  ...  0.000000      0.0  0.0    0.0   0.0   0.0   0.0   \n",
       "2          0.0    0.0  ...  0.000000      0.0  0.0    0.0   0.0   0.0   0.0   \n",
       "3          0.0    0.0  ...  0.000000      0.0  0.0    0.0   0.0   0.0   0.0   \n",
       "4          0.0    0.0  ...  0.000000      0.0  0.0    0.0   0.0   0.0   0.0   \n",
       "\n",
       "   zone  zoonosis  zoonotic  \n",
       "0   0.0       0.0       0.0  \n",
       "1   0.0       0.0       0.0  \n",
       "2   0.0       0.0       0.0  \n",
       "3   0.0       0.0       0.0  \n",
       "4   0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 4480 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = document_tf_idf.todense().tolist()\n",
    "tfidf = pd.DataFrame(dense, columns=feature_names)\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5c67efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/vectorizer.pickle', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84e711d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/title_tf_idf.pickle', 'wb') as file:\n",
    "    pickle.dump(title_tf_idf, file)\n",
    "    \n",
    "with open('data/document_tf_idf.pickle', 'wb') as file:\n",
    "    pickle.dump(document_tf_idf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758480e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
